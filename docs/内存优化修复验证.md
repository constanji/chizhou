# 内存优化修复验证指南

## 修复内容总结

### 1. 文本文件向量化优化
- ✅ 所有文本文件使用流式分块处理
- ✅ 优化字符串操作，减少内存分配
- ✅ 定期触发 GC（每 50 个 chunks）

### 2. Word 文件解析优化
- ✅ 添加文本大小监控日志
- ✅ 及时释放中间变量
- ✅ 修复无限循环问题
- ✅ 添加最大迭代次数限制
- ✅ 强制确保 startIndex 前进

### 3. 向量化过程优化
- ✅ 分批执行 Promise（每批 20 个）
- ✅ 每 5 个 chunks 向量化后触发 GC
- ✅ ONNX 服务每 10 次向量化触发 GC
- ✅ 动态调整批次大小

### 4. GC 支持
- ✅ 启用 `--expose-gc` 标志
- ✅ 定期触发 GC 释放内存

## 验证步骤

### 1. 检查 GC 是否启用

```bash
# 检查环境变量
docker exec Chizhou-API node -e "console.log('NODE_OPTIONS:', process.env.NODE_OPTIONS)"
# 应该输出: --max-old-space-size=4096 --expose-gc

# 检查 GC 是否可用
docker exec Chizhou-API node -e "console.log('global.gc type:', typeof global.gc)"
# 应该输出: function
```

### 2. 测试文件上传

#### 测试小文件（<1MB）
```bash
# 上传一个小的 .txt 或 .docx 文件
# 观察日志中的内存使用情况
docker logs Chizhou-API --tail 50 | grep -i "内存\|memory\|chunk\|分块"
```

#### 测试中等文件（1-10MB）
```bash
# 上传一个中等大小的文件
# 检查是否出现内存泄漏
docker logs Chizhou-API --tail 100 | grep -i "heap\|gc\|内存\|memory"
```

### 3. 监控内存使用

```bash
# 实时监控容器内存使用
docker stats Chizhou-API --no-stream

# 查看详细的内存统计
docker exec Chizhou-API node -e "console.log(JSON.stringify(process.memoryUsage(), null, 2))"
```

### 4. 检查日志

关键日志信息：
- `[WordParseService] 解析后文本长度: X 字符`
- `[WordParseService] 开始分块: 文本长度=X, chunkSize=1000, 最大迭代次数=X`
- `[WordParseService] 分块完成: 迭代次数=X, 生成chunks=X`
- `[uploadVectors] 开始向量化前内存: heapUsed=XMB`
- `[uploadVectors] 批次 X 完成后内存: heapUsed=XMB`

## 预期结果

### ✅ 正常情况
- GC 可用（`typeof global.gc === 'function'`）
- 文件上传成功
- 内存使用稳定，不会持续增长
- 日志显示分块和向量化完成

### ❌ 如果仍有问题
- 检查日志中的文本长度和迭代次数
- 检查是否有无限循环警告
- 检查内存使用是否持续增长
- 查看是否有 GC 触发的日志

## 故障排查

### 问题：GC 不可用
```bash
# 检查容器环境变量
docker exec Chizhou-API env | grep NODE_OPTIONS

# 如果缺少 --expose-gc，需要重启容器
docker compose -f deploy-compose.yml restart api
```

### 问题：内存仍然泄漏
1. 检查日志中的文本长度
2. 检查是否有无限循环警告
3. 检查迭代次数是否异常
4. 考虑进一步降低批次大小

### 问题：文件上传失败
1. 查看完整错误日志
2. 检查文件大小和格式
3. 检查数据库连接
4. 检查磁盘空间

## 性能优化建议

如果内存使用仍然较高，可以：
1. 进一步降低批次大小（BATCH_SIZE）
2. 增加 GC 触发频率
3. 考虑限制文件大小
4. 使用更小的 chunkSize（如 500 而不是 1000）
